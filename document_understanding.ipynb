{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "document_understanding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/LDA-Demonstration/blob/main/document_understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhGNEf8GxBVD"
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm as tqdm\n",
        "import random\n",
        "import joblib\n",
        "import time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEtFLTZ7xBVJ"
      },
      "source": [
        "%%capture .logs\n",
        "# Getting Text Processing Tools\n",
        "\n",
        "!pip install spacy\n",
        "nltk.download('all')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcGR8siZxBVL"
      },
      "source": [
        "# Importing Tools\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "\n",
        "wordlist = words.words()\n",
        "\n",
        "import spacy\n",
        "\n",
        "stopword_set = set(stopwords.words('english'))\n",
        "for idx in range(len(wordlist)):\n",
        "    wordlist[idx] = wordlist[idx].lower()\n",
        "wordlist = list(set(wordlist))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKnOwp8fxBVN"
      },
      "source": [
        "with open('train.json', 'r+') as f:\n",
        "    records = json.load(f)\n",
        "\n",
        "with open('test.json', 'r') as f:\n",
        "    gold_test_list = json.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRHw7y0T-PX5"
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "for item in records:\n",
        "  X_train.append(item['content'])\n",
        "  Y_train.append(item['label'])\n",
        "\n",
        "for item in gold_test_list:\n",
        "  X_test.append(item['content'])\n",
        "  Y_test.append(item['label'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmjqtLixBVO"
      },
      "source": [
        "def clean(s):\n",
        "    # takes an input string\n",
        "    # preprocesses it for the tf-idf vectorizer\n",
        "    s.replace(\"\\n\", \" \")\n",
        "    tokens = word_tokenize(s)\n",
        "    output = \"\"\n",
        "    \n",
        "    for token in tokens:\n",
        "        unit = token.strip().lower()\n",
        "        if unit in stopword_set or unit in punctuation:\n",
        "            continue\n",
        "        output = output + \" \" + unit\n",
        "        \n",
        "    return output.strip()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF5MOGLYxBVR"
      },
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "        sublinear_tf = True,\n",
        "        norm = \"l2\",\n",
        "        encoding = 'utf-8',\n",
        "        max_features = 512,\n",
        "        stop_words = 'english',\n",
        "        ngram_range = (1, 3),\n",
        "        strip_accents = 'unicode',\n",
        "        smooth_idf = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ6h7HVrxBVS",
        "outputId": "da0e6fd9-d2c2-4299-e37d-2564c6685904"
      },
      "source": [
        "# To verify correctness of Vectorizer\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "print(np.shape(X_train_vec))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV5U_ZclxBVT",
        "outputId": "2f21ed80-dece-49dd-e1b9-0258c5a2d2b8"
      },
      "source": [
        "print(\"Size of Train: \" + str(len(X_train)))\n",
        "print(\"Size of Test: \" + str(len(X_test)))\n",
        "max_feature_size = 10000"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Train: 25000\n",
            "Size of Test: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CXY6994xBVT"
      },
      "source": [
        "def train(X, y, active = 'identity', solve = 'sgd', approach = 'mlp'):\n",
        "    start = time.time()\n",
        "    vec = vectorizer.fit(X)\n",
        "    X_train_vec = vec.transform(X)\n",
        "    \n",
        "    if approach == 'lda':\n",
        "        model = LinearDiscriminantAnalysis()\n",
        "        model.fit(X_train_vec.toarray(), y)\n",
        "    \n",
        "    elif approach == 'mlp':\n",
        "        model = MLPClassifier(alpha = 0,\n",
        "                              hidden_layer_sizes = (512, 1024, 512, 256, 128, 64, 32, 16, 8, 4, 1),\n",
        "                              random_state = 2020,\n",
        "                              activation = active,\n",
        "                              max_iter = int(1e3),\n",
        "                              solver = solve,\n",
        "                              learning_rate = 'adaptive',\n",
        "                              early_stopping = True,\n",
        "                              momentum = 0.9,\n",
        "                              batch_size = 512)\n",
        "        \n",
        "        model.fit(X_train_vec, y)\n",
        "    \n",
        "    end = time.time()\n",
        "    time_to_train = int(round(end - start))\n",
        "\n",
        "    hours = int(time_to_train / 3600)\n",
        "    minutes = int(int(time_to_train % 3600) / 60)\n",
        "    seconds = int(time_to_train % 60)\n",
        "\n",
        "    print()\n",
        "    print('Time taken for training: ' + str(hours).zfill(2) + ':' +\n",
        "          str(minutes).zfill(2) + ':' + str(seconds).zfill(2))\n",
        "    return vec, model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlUIOFTbxBVW"
      },
      "source": [
        "def get_res(vec, clf):\n",
        "    X_test_vec = vec.transform(X_test)\n",
        "    pred_Y_test = clf.predict(X_test_vec)\n",
        "    print(\"Number of Features: \" + str(np.shape(X_test_vec)[1]))\n",
        "    print(classification_report(Y_test, pred_Y_test))\n",
        "    return"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U17Vqa9XxBVX"
      },
      "source": [
        "# Best Setting for the tf-idf vectorizer based on the LDA Scheme\n",
        "# sublinear_tf and smooth_idf set to True\n",
        "# norm set to 'l2'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6FJ0MyqxBVX",
        "outputId": "5de89ea4-07f3-4da8-978d-d93109f7fc1b"
      },
      "source": [
        "# To Try out all possibilities\n",
        "try_all = False\n",
        "\n",
        "if try_all == True:\n",
        "    activations = ['identity', 'tanh', 'relu']\n",
        "    solvers = ['adam', 'sgd', 'lbfgs']\n",
        "else:\n",
        "    activations = ['tanh']\n",
        "    solvers = ['sgd']\n",
        "\n",
        "for active in activations:\n",
        "    for solver in solvers:\n",
        "        if active == 'tanh' and solver == 'lbfgs':\n",
        "            continue\n",
        "        vec, model = train(X_train, Y_train, active, solver)\n",
        "        print(\"Hidden Layer Activation = \" + str(active) + \", Solver = \" + str(solver))\n",
        "        get_res(vec, model)\n",
        "        \n",
        "# Comments: ReLU does not perform well\n",
        "# tanh activation with sgd solver gave the best results"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken for training: 00:29:38\n",
            "Hidden Layer Activation = tanh, Solver = sgd\n",
            "Number of Features: 512\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     12500\n",
            "           1       0.82      0.85      0.84     12500\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.83      0.83      0.83     25000\n",
            "weighted avg       0.83      0.83      0.83     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Cr4A2GxBVX",
        "outputId": "4eba0c3e-05ed-477a-972a-3c4198490823"
      },
      "source": [
        "# Testing out a basic pipeline\n",
        "pipe = Pipeline([('Feature Builder', vec), ('Classifier', model)])\n",
        "pred_Y_test = pipe.predict(X_test)\n",
        "print(classification_report(Y_test, pred_Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     12500\n",
            "           1       0.82      0.85      0.84     12500\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.83      0.83      0.83     25000\n",
            "weighted avg       0.83      0.83      0.83     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFgTyEV3xBVY"
      },
      "source": [
        "# K-fold Cross Validation\n",
        "\n",
        "X = X_train\n",
        "Y = Y_train\n",
        "\n",
        "def cross_val(algo = 'mlp', splits = 5):\n",
        "    global X, Y\n",
        "    splits = int(splits)\n",
        "    if splits > 9 or splits < 3:\n",
        "        splits = 5\n",
        "    print(\"Classification Technique: \" + str(algo))\n",
        "    kf = KFold(n_splits = splits, shuffle = True, random_state = 2020)\n",
        "    index = 1    \n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train = []\n",
        "        X_test = []\n",
        "        Y_train = []\n",
        "        Y_test = []\n",
        "\n",
        "        for idx in train_index:\n",
        "            X_train.append(X[idx])\n",
        "            Y_train.append(Y[idx])\n",
        "\n",
        "        for idx in test_index:\n",
        "            X_test.append(X[idx])\n",
        "            Y_test.append(Y[idx])\n",
        "\n",
        "        if algo == 'lda':\n",
        "            vec, model = train(X_train, Y_train, '', '', 'lda')\n",
        "        else:\n",
        "            vec, model = train(X_train, Y_train, 'tanh', 'sgd', 'mlp')\n",
        "\n",
        "        pipe = Pipeline([('Feature Builder', vec), ('Classifier', model)])\n",
        "        pred_Y_test = pipe.predict(X_test)\n",
        "\n",
        "        print(\"Fold Index: \" + str(index))\n",
        "        index += 1\n",
        "        print(classification_report(Y_test, pred_Y_test))\n",
        "        \n",
        "    return"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILBsC3-pxBVZ",
        "outputId": "7fb42812-a07f-4b44-8dc4-ff892234f400"
      },
      "source": [
        "# Performing K-Fold Cross Validation using LDA\n",
        "cross_val('lda', splits = 3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Technique: lda\n",
            "\n",
            "Time taken for training: 00:00:37\n",
            "Fold Index: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83      4183\n",
            "           1       0.82      0.84      0.83      4151\n",
            "\n",
            "    accuracy                           0.83      8334\n",
            "   macro avg       0.83      0.83      0.83      8334\n",
            "weighted avg       0.83      0.83      0.83      8334\n",
            "\n",
            "\n",
            "Time taken for training: 00:00:36\n",
            "Fold Index: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.81      0.83      4166\n",
            "           1       0.82      0.85      0.83      4167\n",
            "\n",
            "    accuracy                           0.83      8333\n",
            "   macro avg       0.83      0.83      0.83      8333\n",
            "weighted avg       0.83      0.83      0.83      8333\n",
            "\n",
            "\n",
            "Time taken for training: 00:00:37\n",
            "Fold Index: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83      4151\n",
            "           1       0.82      0.86      0.84      4182\n",
            "\n",
            "    accuracy                           0.83      8333\n",
            "   macro avg       0.83      0.83      0.83      8333\n",
            "weighted avg       0.83      0.83      0.83      8333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LovufthcxBVZ",
        "outputId": "60abf3fc-0f71-4d40-98f8-4cfcb9ea4e2c"
      },
      "source": [
        "# Performing K-Fold Cross Validation using MLP\n",
        "cross_val('mlp', splits = 3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Technique: mlp\n",
            "\n",
            "Time taken for training: 00:46:05\n",
            "Fold Index: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.79      4183\n",
            "           1       0.79      0.80      0.79      4151\n",
            "\n",
            "    accuracy                           0.79      8334\n",
            "   macro avg       0.79      0.79      0.79      8334\n",
            "weighted avg       0.79      0.79      0.79      8334\n",
            "\n",
            "\n",
            "Time taken for training: 00:12:51\n",
            "Fold Index: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.35      0.47      4166\n",
            "           1       0.57      0.88      0.69      4167\n",
            "\n",
            "    accuracy                           0.61      8333\n",
            "   macro avg       0.66      0.61      0.58      8333\n",
            "weighted avg       0.66      0.61      0.58      8333\n",
            "\n",
            "\n",
            "Time taken for training: 00:11:31\n",
            "Fold Index: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.53      0.57      4151\n",
            "           1       0.59      0.68      0.63      4182\n",
            "\n",
            "    accuracy                           0.61      8333\n",
            "   macro avg       0.61      0.61      0.60      8333\n",
            "weighted avg       0.61      0.61      0.60      8333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEQxvbr3xBVa",
        "outputId": "2b7f77e2-d090-470f-b4f3-624ae65d1374"
      },
      "source": [
        "# Training a LDA Classifier on the complete dataset\n",
        "# And saving the full pipeline into a Model\n",
        "\n",
        "vec, model = train(X, Y, '', '', 'lda')\n",
        "\n",
        "pipe = Pipeline([('Feature Builder', vec), ('Classifier', model)])\n",
        "joblib.dump(pipe, \"tf-idf_lda_model.pkl\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken for training: 00:00:59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf-idf_lda_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00z5qJsExBVa",
        "outputId": "044624cb-e96a-493f-eb1f-7f03a40925df"
      },
      "source": [
        "# Training a MLP Classifier on the complete dataset\n",
        "# And saving the full pipeline into a Model\n",
        "\n",
        "vec, model = train(X, Y, 'tanh', 'sgd', 'mlp')\n",
        "\n",
        "pipe = Pipeline([('Feature Builder', vec), ('Classifier', model)])\n",
        "joblib.dump(pipe, \"tf-idf_mlp_model.pkl\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Time taken for training: 00:27:13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf-idf_mlp_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8o40jQYxBVa",
        "outputId": "7bbdef96-7821-49a4-e283-973a191cc840"
      },
      "source": [
        "# Testing out the saved pipeline on all sample datapoints\n",
        "saved_pipe = joblib.load(\"tf-idf_lda_model.pkl\")\n",
        "\n",
        "pred_Y_all = saved_pipe.predict(X)\n",
        "print(classification_report(Y, pred_Y_all))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84     12500\n",
            "           1       0.83      0.86      0.85     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.84      0.84      0.84     25000\n",
            "weighted avg       0.84      0.84      0.84     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WzlKu7gxBVa",
        "outputId": "64b225b3-0ca8-47b6-825b-0f429bb1d59d"
      },
      "source": [
        "# Testing out Saved LDA Model on Test Data\n",
        "\n",
        "saved_pipe = joblib.load(\"tf-idf_lda_model.pkl\")\n",
        "\n",
        "X_gold_test = []\n",
        "Y_gold_test = []\n",
        "\n",
        "for unit in gold_test_list:\n",
        "    X_gold_test.append(unit['content'])\n",
        "    Y_gold_test.append(unit['label'])\n",
        "    \n",
        "pred_Y_gold_test = saved_pipe.predict(X_gold_test)\n",
        "print(classification_report(Y_gold_test, pred_Y_gold_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83     12500\n",
            "           1       0.82      0.85      0.84     12500\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.83      0.83      0.83     25000\n",
            "weighted avg       0.83      0.83      0.83     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdLrWo0hxBVa",
        "outputId": "d76a88b4-bb9b-496c-d49f-7a247a8f48aa"
      },
      "source": [
        "# Testing out Saved MLP Model on Test Data\n",
        "\n",
        "saved_pipe = joblib.load(\"tf-idf_mlp_model.pkl\")\n",
        "\n",
        "X_gold_test = []\n",
        "Y_gold_test = []\n",
        "\n",
        "for unit in gold_test_list:\n",
        "    X_gold_test.append(unit['content'])\n",
        "    Y_gold_test.append(unit['label'])\n",
        "    \n",
        "pred_Y_gold_test = saved_pipe.predict(X_gold_test)\n",
        "print(classification_report(Y_gold_test, pred_Y_gold_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83     12500\n",
            "           1       0.82      0.85      0.84     12500\n",
            "\n",
            "    accuracy                           0.83     25000\n",
            "   macro avg       0.83      0.83      0.83     25000\n",
            "weighted avg       0.83      0.83      0.83     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEt9QxQDxBVf"
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}